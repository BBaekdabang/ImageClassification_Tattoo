{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMmyaRs12my7"
      },
      "outputs": [],
      "source": [
        "pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ],
      "metadata": {
        "id": "dlAvr6TAH2Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhBguxio4Z0D"
      },
      "source": [
        "#Unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEK_UwcV4FEn"
      },
      "outputs": [],
      "source": [
        "!unzip -q tatoo1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8zFmVuX4cth"
      },
      "outputs": [],
      "source": [
        "import splitfolders\n",
        "\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AesXWFmy4kC3",
        "outputId": "ec6478b5-85ea-44fe-fd14-71094224db27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['blackwork', 'old_new_school', 'polynesian', 'ilezumi']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "folder_path = '/content/tatoo'\n",
        "label_names = os.listdir(folder_path)\n",
        "label_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1e7rJef4w8M"
      },
      "outputs": [],
      "source": [
        "dataset = {}\n",
        "\n",
        "# 이미지와 라벨 리스트에 담기\n",
        "for label in os.listdir(folder_path):\n",
        "    sub_path = folder_path+'/'+label+'/'\n",
        "    dataset[label] = []\n",
        "    for filename in os.listdir(sub_path):\n",
        "        dataset[label].append(sub_path+filename)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQTdPMwc4y1U"
      },
      "outputs": [],
      "source": [
        "!mkdir resized\n",
        "\n",
        "!mkdir resized/blackwork\n",
        "!mkdir resized/ilezumi\n",
        "!mkdir resized/old_new_school\n",
        "!mkdir resized/polynesian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ32JuuX417l"
      },
      "outputs": [],
      "source": [
        "dataset.items()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resize"
      ],
      "metadata": {
        "id": "-cqDUXUsD4nb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRICYH0T46g1"
      },
      "outputs": [],
      "source": [
        "for label, filenames in dataset.items():\n",
        "    for filename in filenames:\n",
        "        img = cv2.imread(filename)\n",
        "\n",
        "        # 이미지의 x, y가 224이 넘을 경우 작게해주기\n",
        "        percent = 1\n",
        "        if(img.shape[1] > img.shape[0]) :       # 이미지의 가로가 세로보다 크면 가로를 640으로 맞추고 세로를 비율에 맞춰서\n",
        "            percent = 300/img.shape[1]\n",
        "        else :\n",
        "            percent = 300/img.shape[0]\n",
        "\n",
        "        img = cv2.resize(img, dsize=(0, 0), fx=percent, fy=percent, interpolation=cv2.INTER_LINEAR)\n",
        "                # 이미지 범위 지정\n",
        "        y,x,h,w = (0,0,img.shape[0], img.shape[1])\n",
        "\n",
        "        # 그림 주변에 검은색으로 칠하기\n",
        "        w_x = (300-(w-x))/2  # w_x = (224 - 그림)을 뺀 나머지 영역 크기 [ 그림나머지/2 [그림] 그림나머지/2 ]\n",
        "        h_y = (300-(h-y))/2\n",
        "\n",
        "        if(w_x < 0):         # 크기가 -면 0으로 지정.\n",
        "            w_x = 0\n",
        "        elif(h_y < 0):\n",
        "            h_y = 0\n",
        "\n",
        "        M = np.float32([[1,0,w_x], [0,1,h_y]])  #(2*3 이차원 행렬)\n",
        "        img_re = cv2.warpAffine(img, M, (300, 300)) #이동변환  \n",
        "       \n",
        "        # cv2.imwrite('{0}.jpg',image .format(file)) #파일저장\n",
        "        cv2.imwrite('/content/resized/{0}/{1}'.format(label, filename.split(\"/\")[-1]) , img_re)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GymOG_UG6hoS",
        "outputId": "efb34fa6-c8e0-4811-ae03-0d1d17840d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 4677 files [00:00, 7905.66 files/s]\n"
          ]
        }
      ],
      "source": [
        "splitfolders.ratio('resized', output='dataset', seed=77, ratio=(0.6, 0.2, 0.2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Set"
      ],
      "metadata": {
        "id": "BAJHHVilEExP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLDSCtav74Kx",
        "outputId": "d1c216d8-51a8-452b-a262-e203b97d2e9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2805, 300, 300, 3), (2805,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "folder_path = '/content/dataset/train'\n",
        "dataset = {}\n",
        "\n",
        "# 이미지와 라벨 리스트에 담기\n",
        "for label in os.listdir(folder_path):\n",
        "    sub_path = folder_path+'/'+label+'/'\n",
        "    dataset[label] = []\n",
        "    for filename in os.listdir(sub_path):\n",
        "        dataset[label].append(sub_path+filename)\n",
        "\n",
        "label2index = {'blackwork' : 0, 'ilezumi' : 1 , 'old_new_school' : 2 , 'polynesian' : 3\n",
        "               }\n",
        "\n",
        "x_train, y_train = [], []\n",
        "\n",
        "for label, filenames in dataset.items():\n",
        "    for filename in filenames:\n",
        "        image = cv2.imread(filename)\n",
        "\n",
        "        x_train.append(image)\n",
        "        y_train.append(label2index[label])\n",
        "\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "x_train = x_train.astype('float32')\n",
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgXrZK9qV0yH"
      },
      "source": [
        "#Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXbLZu3yV0MY"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNlfEpMeWBPs"
      },
      "outputs": [],
      "source": [
        "for label in  os.listdir(folder_path):\n",
        "    label_path = folder_path + '/' + label + '/'\n",
        "    for filename in os.listdir(label_path): \n",
        "        filepath = label_path + filename\n",
        "\n",
        "        img = load_img(filepath)\n",
        "        # img 출력\n",
        "        # plt.imshow(img)\n",
        "        # break\n",
        "        x = img_to_array(img)\n",
        "        # x.shape 출력\n",
        "        # print(x.shape)\n",
        "        # break\n",
        "        x = x.reshape((1,) + x.shape)\n",
        "\n",
        "        i = 0\n",
        "        # flow : augmentation 함수. 계속 반복하므로, break 필요\n",
        "        for batch in datagen.flow(x, batch_size=1,\n",
        "                                save_to_dir=label_path, save_prefix=label, save_format='jpg'):\n",
        "          # break\n",
        "            i += 1\n",
        "            if i > 3:\n",
        "                break  \n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#After Data Augmentaion - Train Set"
      ],
      "metadata": {
        "id": "mLmYdyeiEzcU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QcIa740WHyN",
        "outputId": "3f179cef-2d31-41e9-d56e-607250910d08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12546, 300, 300, 3), (12546,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "folder_path = '/content/dataset/train'\n",
        "dataset = {}\n",
        "\n",
        "# 이미지와 라벨 리스트에 담기\n",
        "for label in os.listdir(folder_path):\n",
        "    sub_path = folder_path+'/'+label+'/'\n",
        "    dataset[label] = []\n",
        "    for filename in os.listdir(sub_path):\n",
        "        dataset[label].append(sub_path+filename)\n",
        "\n",
        "label2index = {'blackwork' : 0, 'ilezumi' : 1 , 'old_new_school' : 2 , 'polynesian' : 3\n",
        "               }\n",
        "\n",
        "x_train, y_train = [], []\n",
        "\n",
        "for label, filenames in dataset.items():\n",
        "    for filename in filenames:\n",
        "        image = cv2.imread(filename)\n",
        "\n",
        "        x_train.append(image)\n",
        "        y_train.append(label2index[label])\n",
        "\n",
        "x_train, y_train = np.array(x_train), np.array(y_train) \n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "\n",
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIByX8xrWZyp"
      },
      "source": [
        "#Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9SHZ4M4WZii",
        "outputId": "847278de-9440-4c18-9087-2f73dd877daf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((934, 300, 300, 3), (934,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "folder_path = '/content/dataset/val'\n",
        "dataset = {}\n",
        "\n",
        "# 이미지와 라벨 리스트에 담기\n",
        "for label in os.listdir(folder_path):\n",
        "    sub_path = folder_path+'/'+label+'/'\n",
        "    dataset[label] = []\n",
        "    for filename in os.listdir(sub_path):\n",
        "        dataset[label].append(sub_path+filename)\n",
        "\n",
        "x_val, y_val = [], []\n",
        "\n",
        "for label, filenames in dataset.items():\n",
        "    for filename in filenames:\n",
        "        image = cv2.imread(filename)\n",
        "        x_val.append(image)\n",
        "        y_val.append(label2index[label])\n",
        "\n",
        "x_val, y_val= np.array(x_val), np.array(y_val)\n",
        "\n",
        "x_val = x_val.astype('float32')\n",
        "\n",
        "x_val.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Set"
      ],
      "metadata": {
        "id": "RiL0fA2OGgFJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRpSJ4ZcWvSq",
        "outputId": "240b728d-644f-4b42-d51a-29e97c75055e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((938, 300, 300, 3), (938,))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "folder_path = '/content/dataset/test'\n",
        "dataset = {}\n",
        "\n",
        "for label in os.listdir(folder_path):\n",
        "    sub_path = folder_path+'/'+label+'/'\n",
        "    dataset[label] = []\n",
        "    for filename in os.listdir(sub_path):\n",
        "        dataset[label].append(sub_path+filename)\n",
        "\n",
        "x_test, y_test = [], []\n",
        "\n",
        "for label, filenames in dataset.items():\n",
        "    for filename in filenames:\n",
        "        image = cv2.imread(filename)\n",
        "\n",
        "        x_test.append(image)\n",
        "        y_test.append(label2index[label])\n",
        "\n",
        "x_test, y_test = np.array(x_test), np.array(y_test)\n",
        "\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpYQf5ESW31p"
      },
      "source": [
        "#Zero Centering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZCUO61KW3g8"
      },
      "outputs": [],
      "source": [
        "def zero_mean(image):\n",
        "    return np.mean(image, axis=0)\n",
        "\n",
        "zero_mean_img = zero_mean(x_train)\n",
        "\n",
        "x_train -= zero_mean_img\n",
        "\n",
        "x_val -= zero_mean_img\n",
        "x_test -= zero_mean_img"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN"
      ],
      "metadata": {
        "id": "zOmdJd1aggEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu',input_shape=(300, 300, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs = 15, validation_data=(x_val, y_val), verbose = 1)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "KvEm-rsRM16P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "iP_6TBCeEH-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet152, ResNet50, VGG16, VGG19, AlexNet"
      ],
      "metadata": {
        "id": "mJCu5CX5ETyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet152(include_top=False, input_shape = (300,300,3), weights = 'imagenet')\n",
        "\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:400]: \n",
        "    layer.trainable = False\t\t\t\n",
        "\n",
        "inputs = tf.keras.Input(shape=(300, 300, 3))\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "x = tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:])(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x= tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam( learning_rate= 0.0001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs = 15, validation_data=(x_val, y_val), verbose = 1)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "jtekeeuSEHhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation - 1"
      ],
      "metadata": {
        "id": "tM4eZGYZkhHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet152(include_top=False, input_shape = (300,300,3), weights = 'imagenet')\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:400]: \n",
        "    layer.trainable = False\t\t\t\n",
        "\n",
        "inputs = tf.keras.Input(shape=(300, 300, 3))\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "x = tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:])(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x= tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam( learning_rate= 0.0001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs = 15, validation_data=(x_val, y_val), verbose = 1)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "MIpvA4XzkJsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation - 2"
      ],
      "metadata": {
        "id": "u0B4X59wk2Ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet152(include_top=False, input_shape = (300,300,3), weights = 'imagenet')\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:400]: \n",
        "    layer.trainable = False\t\t\t\n",
        "\n",
        "inputs = tf.keras.Input(shape=(300, 300, 3))\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "x = tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:])(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x= tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam( learning_rate= 0.0001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs = 15, validation_data=(x_val, y_val), verbose = 1)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "id": "1An-9yCpkdVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyOurXKuMbCm"
      },
      "source": [
        "1. 전체 재학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCX67JZVMhA5"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet152(include_top = False, input_shape = (300, 300,3), weights = 'imagenet')\n",
        "\n",
        "base_model.trainable = True\t\t\t\t\n",
        "\n",
        "# for layer in base_model.layers[:]:\t\n",
        "#   print(layer.name, layer.trainable)\t\n",
        "\n",
        "inputs = tf.keras.Input(shape=(300, 300, 3))\n",
        "\n",
        "x = base_model(inputs, training = False)\n",
        "\n",
        "x = tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:])(x)\n",
        "x = tf.keras.layers.Dense(256, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(128, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\", \n",
        "    factor=0.1, # new_lr = lr * factor.\n",
        "    patience=2,\n",
        "    min_delta=0.0001, # threshold for measuring the new optimum, to only focus on significant changes.  \n",
        "    min_lr=0\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, epochs = 15, validation_data=(x_val, y_val), verbose = 1, callbacks = [callback])\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CGUXXG_LxXb"
      },
      "source": [
        "2. 분류기만 재학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLNgUU0kL-jL"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet152(include_top = False, input_shape = (300, 300,3), weights = 'imagenet')\t\t\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(300, 300, 3))\n",
        "\n",
        "x = base_model(inputs, training = False)\n",
        "\n",
        "x = tf.keras.layers.Flatten(input_shape = base_model.output_shape[1:])(x)\n",
        "x = tf.keras.layers.Dense(2048, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(128, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\", \n",
        "    factor=0.1, # new_lr = lr * factor.\n",
        "    patience=2,\n",
        "    min_delta=0.0001, # threshold for measuring the new optimum, to only focus on significant changes.  \n",
        "    min_lr=0\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, epochs = 20, validation_data=(x_val, y_val), verbose = 1, callbacks = [callback])\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf0tdUfJa8I_"
      },
      "source": [
        "2-1 Fine_Tune(미세조정)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhprR7Qda_nE"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam( learning_rate= 0.0001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs = 10, validation_data=(x_val, y_val))\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7AtBQ3UKqa-"
      },
      "source": [
        "3. 하위층 일부 재학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkX-hOMTyHM-"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet152(include_top = False, input_shape = (300, 300, 3), weights = 'imagenet')\n",
        "\n",
        "for layer in base_model.layers[:-20]: \n",
        "    layer.trainable = False\t\t\t\n",
        "\n",
        "inputs = tf.keras.Input(shape=(300, 300, 3))\n",
        "\n",
        "x = base_model(inputs, training = False)\n",
        "\n",
        "x = tf.keras.layers.Flatten(input_shape=base_model.output_shape[1:])(x)\n",
        "x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\", \n",
        "    factor=0.1, # new_lr = lr * factor.\n",
        "    patience=2,\n",
        "    min_delta=0.0001, # threshold for measuring the new optimum, to only focus on significant changes.  \n",
        "    min_lr=0\n",
        ")                \n",
        "\n",
        "model.fit(x_train, y_train, epochs = 15, validation_data=(x_val, y_val), verbose = 1, callbacks = [callback])\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQegx45ULkO2"
      },
      "source": [
        "3-1 Fine-Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2KI2zQz4JAj"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam( learning_rate= 0.0001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
        "\n",
        "model.fit(x_train, y_train, epochs = 10, validation_data=(x_val, y_val), callbacks = [early])\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(test_acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}